
litellm_settings:
  drop_params: true
  set_verbose: true
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]
  
model_list:
- litellm_params:
    api_base: http://ollama:11434/v1
    api_key: sk-1234
    model: openai/llama3
  model_name: llama3

- litellm_params:
    api_base: http://ollama:11434/v1
    api_key: sk-1234
    model: openai/llama2
  model_name: llama2

- litellm_params:
    api_base: http://ollama:11434/v1
    api_key: sk-1234
    model: openai/gemma
  model_name: gemma

- litellm_params:
    api_key: "os.environ/ANTHROPIC_API_KEY"
    model: claude-3-haiku-20240307
    max_tokens: 2000
  model_name: claude-3-haiku-20240307-2k

- litellm_params:
    api_key: "os.environ/ANTHROPIC_API_KEY"
    model: claude-3-sonnet-20240229
    max_tokens: 2000
  model_name: claude-3-sonnet-20240229-2k

- litellm_params: 
    model: anthropic.claude-3-haiku-20240307-v1:0
    ### [OPTIONAL] SET AWS REGION ###
    aws_region_name: us-west-2
  model_name: aws_anthropic.claude-3-haiku-20240307-v1:0

# - litellm_params: 
#     model: anthropic.claude-3-haiku-20240307-v1:0
#     ### [OPTIONAL] SET AWS REGION ###
#     aws_region_name: us-west-2
#   model_name: aws_anthropic.claude-3-haiku-20240307-v1:0

- litellm_params: 
    model: anthropic.claude-3-sonnet-20240229-v1:0
    ### [OPTIONAL] SET AWS REGION ###
    aws_region_name: us-west-2
  model_name: aws_anthropic.claude-3-sonnet-20240229-v1:0
  
# - litellm_params: 
#     model: anthropic.claude-3-sonnet-20240229-v1:0
#     ### [OPTIONAL] SET AWS REGION ###
#     aws_region_name: us-west-2
#   model_name: aws_anthropic.claude-3-sonnet-20240229-v1:0